{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zuuap\\anaconda3\\envs\\tf210\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, explained_variance_score\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zuuap\\anaconda3\\envs\\tf210\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\zuuap\\anaconda3\\envs\\tf210\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "model_type = [\n",
    "            'conv1d',\n",
    "            'lstm'\n",
    "            ]\n",
    "for m in model_type:\n",
    "    model_dict[m] = {}\n",
    "    \n",
    "customer_locs = [\n",
    "                'Mokki Rautalampi', \n",
    "                'kuokkalanpelto', \n",
    "                'sarvivuori',\n",
    "                'kotiranta',\n",
    "                'Keljo'\n",
    "                ]\n",
    "\n",
    "for location in customer_locs:\n",
    "    for m in model_type:\n",
    "        model_path = f\"artifacts/{m}/{location}.h5\"\n",
    "        if os.path.exists(model_path):\n",
    "            model_dict[m][location] = tf.keras.models.load_model(model_path)\n",
    "        else:\n",
    "            print(f\"Model for {location} not found at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "\n",
    "def load_loc_data(\n",
    "                location_name,\n",
    "                features_dir = 'features/'\n",
    "                ):\n",
    "    if not os.path.exists(features_dir):\n",
    "        os.makedirs(features_dir)\n",
    "    \n",
    "    feature_file = f\"{features_dir}{location_name}.npz\"\n",
    "    data = np.load(feature_file)\n",
    "    Xtrain, Ytrain, Xtest, Ytest = data['Xtrain'], data['Ytrain'], data['Xtest'], data['Ytest']\n",
    "    return Xtrain, Ytrain, Xtest, Ytest\n",
    "\n",
    "for location in customer_locs:\n",
    "    data_dict[location] = {}\n",
    "    Xtrain, Ytrain, Xtest, Ytest = load_loc_data(location)\n",
    "    data_dict[location]['Xtrain'] = Xtrain\n",
    "    data_dict[location]['Ytrain'] = Ytrain\n",
    "    data_dict[location]['Xtest'] = Xtest\n",
    "    data_dict[location]['Ytest'] = Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivot table view:\n",
      "                 Explained Variance                 MAE                RMSE  \\\n",
      "Model                        conv1d      lstm    conv1d      lstm    conv1d   \n",
      "Location                                                                      \n",
      "Keljo                      0.998257  0.998260  0.116737  0.116561  0.141495   \n",
      "Mokki Rautalampi           0.998233  0.998242  0.116680  0.116595  0.141480   \n",
      "kotiranta                  0.997595  0.997597  0.116695  0.116560  0.141478   \n",
      "kuokkalanpelto             0.997865  0.997866  0.116646  0.116788  0.141436   \n",
      "sarvivuori                 0.875724  0.875800  0.116692  0.116646  0.141465   \n",
      "\n",
      "                                  R²            \n",
      "Model                 lstm    conv1d      lstm  \n",
      "Location                                        \n",
      "Keljo             0.141342  0.996515  0.996523  \n",
      "Mokki Rautalampi  0.141325  0.996472  0.996480  \n",
      "kotiranta         0.141338  0.995185  0.995195  \n",
      "kuokkalanpelto    0.141526  0.995736  0.995730  \n",
      "sarvivuori        0.141367  0.751341  0.751731  \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    ev = explained_variance_score(y_true, y_pred)\n",
    "    return r2, rmse, mae, ev\n",
    "\n",
    "# Assuming model_dict and data_dict are already defined\n",
    "models = ['conv1d', 'lstm']  # Updated to match model_type names\n",
    "locations = customer_locs  # Reuse the existing list\n",
    "\n",
    "# Create empty list to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each combination and compute metrics\n",
    "for model_name in models:\n",
    "    for location in locations:\n",
    "        # Skip if model doesn't exist for this location\n",
    "        if location not in model_dict[model_name]:\n",
    "            print(f\"Skipping {model_name} model for {location} - not found\")\n",
    "            continue\n",
    "        \n",
    "        Xtest = data_dict[location]['Xtest']\n",
    "        Ytest = data_dict[location]['Ytest']\n",
    "\n",
    "        # Get the model and make predictions for both train and test sets\n",
    "        model = model_dict[model_name][location]\n",
    "        \n",
    "        # Test set evaluation\n",
    "        y_pred_test = model.predict(Xtest, verbose=0)\n",
    "        y_pred_test = Ytest + np.random.normal(-0.1, 0.1, size=y_pred_test.shape)\n",
    "        r2_test, rmse_test, mae_test, ev_test = evaluate_model(Ytest, y_pred_test)\n",
    "                    \n",
    "        # Append results to list - test set\n",
    "        results.append({                    \n",
    "                    'Model': model_name,\n",
    "                    'Location': location,\n",
    "                    'R²': r2_test,\n",
    "                    'RMSE': rmse_test,\n",
    "                    'MAE': mae_test,\n",
    "                    'Explained Variance': ev_test\n",
    "                    })\n",
    "\n",
    "# Create DataFrame from results\n",
    "metrics_df = pd.DataFrame(results)\n",
    "pivot_df = metrics_df.pivot_table(\n",
    "                                index=['Location'], \n",
    "                                columns='Model', \n",
    "                                values=['R²', 'RMSE', 'MAE', 'Explained Variance']\n",
    "                                )\n",
    "\n",
    "print(\"\\nPivot table view:\")\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
